<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>wllama Autocomplete</title>
  </head>
  <body>
    <h3>LLM Autocomplete</h3>
    <input type="text" id="transcribed" size="80" placeholder="Enter text..." />
    <button id="suggestBtn">Suggest</button>
    <pre id="output">Suggestions will appear here...</pre>

    <!-- UMD build -->
    <script src="./js/wllama.js"></script>
    <!-- Must be downloaded locally -->
    <script>
      let llama = null
      console.log(window.wllama)
      window.onload = async function () {
        if (!window.wllama) {
          document.getElementById('output').textContent = 'wllama failed to load'
          return
        }
      }
      document.getElementById('output').textContent = 'Loading model...'

      window.addEventListener('load', async () => {
        llama = await window.wllama.LLModel.create({
          modelPath: './modelts/qwen1_5-0_5b-chat-q4_0.gguf', // Local path to model
          wasmPath: './wllama.wasm', // Local path to wasm
        })

        document.getElementById('output').textContent = 'Model loaded. Ready.'
      })

      document.getElementById('suggestBtn').onclick = async () => {
        if (!llama) return

        const input = document.getElementById('transcribed').value.trim()
        if (!input) return

        const prompt = `Suggest 3 good ways to complete this phrase:\n"${input}"\n1.`
        const output = await llama.generate(prompt, { nPredict: 80 })
        document.getElementById('output').textContent = output
      }
    </script>
  </body>
</html>
